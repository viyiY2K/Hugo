---
url: a_record_of_the_new_burnout_worker_hiring_ai
title: æ–°æ™‹ç¤¾ç•œé›‡ä½£ AI å®å½•
toc: true
authors: viyi
tags:
  - AI
  - Python
categories:
  - æœ­è®°
description: æœ¬æ–‡è®°å½•äº†ä¸€ä½ç»æœ›çš„ç¤¾ç•œåˆ©ç”¨ AI å®Œæˆçç¢äº‹é¡¹çš„è‡ªåŠ¨åŒ–è¿‡ç¨‹ã€‚
date: 2025-01-26
lastmod: 2025-01-26
---

> æˆ‘ä»¬è§‰å¾—ï¼Œæ²¡æœ‰å¿…è¦å› ä¸ºä¸–ç•Œè¡¨ç°å¾—è’è°¬ï¼Œæˆ‘ä»¬å°±éšç€å®ƒä¸€èµ·æ¥åšè’è°¬ä¹‹äº‹ã€‚â€”â€”æ–¯è’‚èŠ¬Â·èŒ¨å¨æ ¼ã€Œæ˜¨æ—¥çš„ä¸–ç•Œã€

è¯šç„¶ï¼Œæˆ‘çŸ¥é“ä¸€ä»½å·¥ä½œé‡Œä¸å¯é¿å…çš„ä¼šå­˜åœ¨ Dirty workï¼Œä½†æˆ‘ç¡®å®æ²¡æ–™åˆ°å®ƒå æ®äº†ç»å¤§éƒ¨åˆ†ã€‚ä½œä¸ºæŸä¸ªå¤´éƒ¨åšä¸»å›¢é˜Ÿé‡Œçš„æ–°åª’ä½“è¿è¥ï¼Œæˆ‘æ—¥å¸¸å·¥ä½œé‡Œæœ€æ— èŠçš„æ˜¯ï¼Œç›‘æµ‹è§†é¢‘æƒ…å†µã€æ£€æŸ¥æ˜¯å¦è¾¾æˆ KPI å¹¶ä¸”å®šæ—¶æ”¶å½•ç›¸å…³æ•°æ®ã€‚

è€æ¿å¨˜ç†ç›´æ°”å£®åœ°è¦æ±‚æˆ‘ï¼Œå°±ç®—æ˜¯å‘¨äº”å‘è§†é¢‘ï¼Œå‘¨æœ«ä¹Ÿè¦â€œæ—¶ä¸æ—¶â€çœ‹ä¸€ä¸‹æ•°æ®ã€‚æ˜¯çš„ï¼Œå°±ç®—æ˜¯åŒä¼‘ä¹Ÿå¹¶ä¸ä»£è¡¨æˆ‘æ‹¥æœ‰ç¦»çº¿æƒğŸ™‚ã€‚æˆ‘çš„èŒä¸šç´ å…»å‘Šè¯‰æˆ‘ï¼Œè¿™ç¡®å®æ˜¯åº”å½“çš„ï¼Œè§†é¢‘å‘å‡ºå¹¶ä¸ä»£è¡¨è¿™ä¸ªé¡¹ç›®ç»“æŸäº†ï¼Œè¿è¥ç»´æŠ¤å’Œæ•°æ®åˆ†æä¹Ÿå¾ˆé‡è¦ã€‚

å¦‚æœæˆ‘æœ‰å¯¹åº”çš„èŒæƒï¼Œå¯ä»¥æ ¹æ®æ•°æ®æƒ…å†µåšè¿›ä¸€æ­¥çš„åº”å¯¹ï¼Œæˆ‘æƒ³å®ƒä¸ä¼šæ˜¾å¾—é‚£ä¹ˆæ— èŠã€‚äº‹å®ä¸Šï¼Œæˆ‘æ—¢æ²¡æœ‰é¢„ç®—ç”¨äºæŠ•æµï¼Œä¹Ÿæ— æ³•å‚ä¸å†…å®¹åˆ¶ä½œï¼Œè¿è§†é¢‘çš„æ ‡å°ä¹Ÿæ— æƒè¿‡é—®ã€‚ç”šè‡³ï¼Œåœ¨æˆ‘å¯¹è§†é¢‘è¯„è®ºåŒºåšæ–‡æœ¬æƒ…æ„Ÿåˆ†æçš„æ—¶å€™ï¼Œå¥¹å¯¹ç€æ•°æ®è¡¨è¯„ä»·äº†ä¸€å¥ã€Œæ²¡å¿…è¦ã€ã€‚

å› æ­¤ï¼Œæˆ‘æƒ³å¥¹åªæ˜¯éœ€è¦æˆ‘è½¬æ’­æ•°æ®æƒ…å†µç»™å¥¹ã€‚

ç†è®ºä¸Šæ¥è¯´ï¼Œè¿™ä»¶äº‹å¹¶ä¸éœ€è¦è€—è´¹å¤ªå¤šæ—¶é—´ã€‚å®ƒåªæ˜¯å¾ˆçç¢ï¼ŒB ç«™ã€å¾®åšã€å…¬ä¼—å·ã€æŠ–éŸ³ã€å°çº¢ä¹¦ã€è§†é¢‘å·ï¼Œå…‰æ˜¯ç®€ä¸­å°±æœ‰ 6 ä¸ªå¹³å°ï¼Œå†åŠ ä¸Šæµ·å¤–çš„ YouTubeâ€”â€”è¿™æ„å‘³ç€æˆ‘éœ€è¦æ±‡æ€» 7 ä¸ªå¹³å°çš„æ’­æ”¾é‡ä»¥åŠç›¸å…³çš„äº’åŠ¨æ•°æ®ï¼ˆå®é™…ä¸Šåˆ†å‘æ€»è®¡æ˜¯ 12 ä¸ªå¹³å°ï¼‰ã€‚

ä¸æ­¤åŒæ—¶ï¼Œæˆ‘ä¹Ÿéœ€è¦å…³æ³¨è¿™äº›å¹³å°é‡Œçš„è¯„è®ºï¼Œæ˜¯å¦æœ‰è§‚ä¼—æŒ‡å‡ºè§†é¢‘ä¸­çš„ç‰‡æºé—®é¢˜å’Œäº‹å®æ€§é”™è¯¯ï¼ŒæŠ‘æˆ–æ˜¯å¯¹è®ºè¯è¿‡ç¨‹ã€æµ‹è¯•ç»†èŠ‚çš„è´¨ç–‘ã€‚è¿™äº›æœ‰æŸå“ç‰Œå½¢è±¡çš„è¯„è®ºï¼Œåªä¼šå éå¸¸å°çš„æ¯”ä¾‹ï¼Œä½†ä¸€æ—¦å‡ºç°åˆæ²¡æœ‰åŠæ—¶å“åº”ï¼Œå¾ˆå®¹æ˜“é€ æˆèˆ†æƒ…å±æœºã€‚å½“ç„¶ï¼Œè€ƒè™‘åˆ°åœ¨å„ä¸ªå¹³å°å½±å“åŠ›ä¸åŒï¼Œæˆ‘é€šå¸¸ä¹Ÿåªå…³æ³¨ B ç«™ï¼Œé¡ºå¸¦çœ‹çœ‹å¾®åšå’Œ YouTubeã€‚

è¿™ä¸¤ä»¶äº‹è®©è¿™ä»½å·¥ä½œå¾ˆå¤§ç¨‹åº¦ä¸Šå˜æˆäº† [Bullshit Jobs](https://www.marxists.org/chinese/david-graeber/2018/02.htm)ï¼Œè½¬æ’­æ•°æ®æƒ…å†µæ˜¯åœ¨å……å½“è€æ¿å¨˜çš„ flunkyï¼Œè€Œç´§ç›¯è¯„è®ºåŒºé€šå¸¸éƒ½æ˜¯åœ¨ç»™åˆ¶ä½œå›¢é˜Ÿå½“ duct taperã€‚

æˆ‘ä»¬å¤§å¤šæ•°æ—¶å€™æ¢æºæ˜¯å› ä¸ºè¯„è®ºåŒºæŒ‡å‡ºç”»é¢æ ‡æ³¨é”™è¯¯ã€å‰ªè¾‘å­˜åœ¨è¯¯å¯¼æ€§ã€å­—å¹•é”™è¯¯ç­‰ç‰‡æºé—®é¢˜ï¼Œè€Œå¦‚æœè¿™ä¸ªå›¢é˜Ÿæœ‰åˆç†çš„å®¡ç‰‡æµç¨‹ï¼Œè¿™äº›æ˜¾ç„¶éƒ½å¯ä»¥é¿å…ã€‚å¾ˆä¸å¹¸ï¼Œæˆ‘ç›®ç¹äº†æ’æœŸç´§å¼ å¯¼è‡´æ— æ³•é¢„ç•™å‡ºå†…å®¡æ—¶é—´çš„é¡¹ç›®ç®¡ç†æƒ¨çŠ¶ï¼Œå†åŠ ä¸Šæ›¾ç»å› ä¸ºæ¨åŠ¨å†…å®¡æˆä¸ºé‚£ä¸ªè¢« Shooting çš„ The Messengerï¼Œç°åœ¨åªèƒ½è¡¨ç¤ºæ— èƒ½ä¸ºåŠ›ã€‚

è¿™ç¯‡æ–‡ç« å¹¶ä¸æ˜¯ä¸ºäº†æŠ±æ€¨è¿™ä»½å·¥ä½œï¼Œå°½ç®¡æˆ‘å¯¹è¿™äº›çç¢çš„å·¥ä½œå†…å®¹æ„Ÿåˆ°åŒçƒ¦ï¼Œä½†è¿˜æ˜¯è¯•å›¾åšç‚¹ä»€ä¹ˆè®©å®ƒä¸é‚£ä¹ˆæ— èŠï¼Œæ¯”å¦‚åˆ©ç”¨è‡ªåŠ¨åŒ–å·¥å…·ã€‚

## å®šæ—¶è½¬æ’­è§†é¢‘æ•°æ®

### è‡ªåŠ¨åŒ–è·å–æ•°æ®

ä¸ºäº†é¿å…é‡å¤é€ è½®å­ï¼Œå…ˆåšç‚¹ç®€å•çš„è°ƒç ”ã€‚å¦‚æœåœ¨æœç´¢å¼•æ“æŸ¥è¯¢ã€Œç¤¾åª’çŸ©é˜µç®¡ç†ã€ï¼Œèƒ½å¤ŸæŸ¥è¯¢åˆ°è®¸å¤šå·¥å…·ã€‚è¿™äº›éƒ½æ˜¯ To B çš„æœåŠ¡å•†ï¼Œå¾ˆæ˜¾ç„¶ï¼Œè¢«é›‡ä½£çš„æˆ‘å¤§æ¦‚ç‡æ¯”è¿™äº›å·¥å…·ä¾¿å®œ(ã€‚

æ‰€å¹¸æˆ‘åªéœ€è¦ç›‘æµ‹è§†é¢‘æ•°æ®ï¼Œå¬èµ·æ¥å¾ˆç®€å•â€”â€”åªéœ€è¦å®šæ—¶è·å–å„ä¸ªè§†é¢‘å¹³å°çš„æ•°æ®ï¼Œå†è½¬æ’­åˆ°é£ä¹¦å°±å¯ä»¥äº†ã€‚å®ç°èµ·æ¥ä¹Ÿä¸éš¾ï¼Œå¦‚æœå¹³å°è¶³å¤Ÿå¼€æ”¾çš„è¯ã€‚

è™½ç„¶è¿™ç‚¹å°éœ€æ±‚ä¸æ¶‰åŠä»€ä¹ˆå¤æ‚çš„æŠ€æœ¯æ ˆï¼Œä½†èµ·ç å¾—é€‰å®šæŸç§ç¼–ç¨‹è¯­è¨€å®ç°ã€‚è€ƒè™‘åˆ° Python çš„åº“æ”¯æŒè¶³å¤Ÿä¸°å¯Œâ€¦â€¦ä»é›¶å¼€å§‹å­¦ Pythonï¼Œå¯åŠ¨(bushiã€‚å¦‚æœçœŸçš„ä»é›¶å¼€å§‹å­¦ï¼Œå¤§æ¦‚è¿™ç¯‡æ–‡ç« è¦å†éš¾äº§ä¹…ä¸€ç‚¹ã€‚äº‹å®ä¸Šï¼Œåæ–‡å‡ºç°çš„æ‰€æœ‰ä»£ç  ï¼ŒåŸºæœ¬éƒ½æ˜¯ AI å®Œæˆçš„ï¼Œæ„Ÿè°¢ Monica çš„é»‘äº”æŠ˜æ‰£ğŸ™ã€‚

é•¿è§†é¢‘å¹³å°ä¸­ï¼Œæœ€é‡è¦çš„è«è¿‡äº bilibili å’Œ YouTubeã€‚æ‰€å¹¸è¿™ä¿©éƒ½å¾ˆå‹å¥½ï¼Œå†åŠ ä¸Š [bilibili-api](https://github.com/Nemo2011/bilibili-api) å’Œ [youtube-dl](https://github.com/ytdl-org/youtube-dl) ä¹Ÿæ˜¯å¾ˆå®Œå–„çš„åº“ï¼Œå¾ˆå®¹æ˜“è·å–åˆ°ç‰¹å®šè§†é¢‘çš„æ’­æ”¾é‡å’Œç‚¹èµç­‰æ•°æ®ã€‚

B ç«™ç‰¹å®šè§†é¢‘æ•°æ®æŠ“å–çš„ç¤ºä¾‹ä»£ç å¦‚ä¸‹ï¼š

```python
import asyncio
from bilibili_api import video

async def main() -> None:
    ## æç¤ºç”¨æˆ·è¾“å…¥ BV å·
    bvid = input("è¯·è¾“å…¥ bilibili è§†é¢‘çš„ BV å·ï¼š")
    
    ## å®ä¾‹åŒ– Video ç±»
    v = video.Video(bvid=bvid)
    ## è·å–ä¿¡æ¯
    info = await v.get_info()
    
    ## ç­›é€‰å¹¶è¾“å‡ºæ‰€éœ€ä¿¡æ¯
    output = {
        'æ ‡é¢˜'ï¼šinfo['title']ï¼Œ
        'BV å·': info['bvid'],
        'è§†é¢‘ä½œè€…': info['owner']['name'],
        'å‘å¸ƒæ—¶é—´': info['pubdate'],
        'ç»Ÿè®¡ä¿¡æ¯': {
            'æ’­æ”¾é‡': info['stat']['view'],
            'ç‚¹èµæ•°': info['stat']['like'],
            'è¯„è®ºæ•°': info['stat']['reply'],
            'æŠ•å¸æ•°': info['stat']['coin'],
            'æ”¶è—æ•°': info['stat']['favorite'],
            'å¼¹å¹•æ•°': info['stat']['danmaku']
        }
    }
    
    print(output)

if __name__ == "__main__":
    asyncio.get_event_loop().run_until_complete(main())
```

é€šè¿‡ pip å®‰è£…çš„ youtube-dl æ˜¯ 2021.12.17 çš„ç‰ˆæœ¬ï¼Œè¯¥ç‰ˆè¿‡æ—§ä¸èƒ½é¡ºåˆ©æå–æ•°æ®ï¼Œä¸”æ— æ³•æ›´æ–°ç‰ˆæœ¬ï¼ˆåŸå› æœªçŸ¥ï¼‰ã€‚å› æ­¤è¿™é‡Œæ”¹ç”¨äº† yt-dlpï¼Œè¿™æ˜¯ youtube-dl çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œé€šå¸¸æ›´æ–°æ›´å¿«ï¼ŒåŠŸèƒ½æ›´å¼ºå¤§ã€‚YouTube ç‰¹å®šè§†é¢‘æ•°æ®æŠ“å–çš„ç¤ºä¾‹ä»£ç å¦‚ä¸‹ï¼š

```python
import yt_dlp

def get_video_info(video_url):
    ydl_opts = {
        'quiet': True,  ## å…³é—­è¾“å‡º
        'format': 'best',  ## è·å–æœ€ä½³æ ¼å¼
        'noplaylist': True,  ## ä¸ä¸‹è½½æ’­æ”¾åˆ—è¡¨
    }

    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        info_dict = ydl.extract_info(video_url, download=False)
        title = info_dict.get('title', None)
        view_count = info_dict.get('view_count', None)
        like_count = info_dict.get('like_count', None)
        comment_count = info_dict.get('comment_count', None)

        return title, view_count, like_count, comment_count

video_url = "<https://www.youtube.com/watch?v=>"  ## æ›¿æ¢ä¸ºéœ€è¦çš„è§†é¢‘é“¾æ¥
title, views, likes, comments = get_video_info(video_url)

print(f"æ ‡é¢˜: {title}")
print(f"è§‚çœ‹æ¬¡æ•°: {views}")
print(f"ç‚¹èµæ•°: {likes}")
print(f"è¯„è®ºæ•°: {comments}")
```

æ¥ä¸‹æ¥æ˜¯å¾®åšï¼Œè‡³äºä¸ºä»€ä¹ˆæ˜¯å®ƒï¼Œå› ä¸º [Weibo Spider](https://github.com/dataabc/weiboSpider) æ˜¯ç°æˆçš„å¥½å·¥å…·ã€‚å®˜æ–¹çš„æ–‡æ¡£åªæä¾›äº†[è½¬å‘è¯„è®ºæ•°çš„è¯»å–æ¥å£](https://open.weibo.com/wiki/%E5%BE%AE%E5%8D%9AAPI)ï¼Œè¿˜ç¼ºå°‘ç‚¹èµå’Œè§†é¢‘æ’­æ”¾é‡ã€‚è¿™ä¸ªç¬¬ä¸‰æ–¹çš„å·¥å…·å¯ä»¥è·å–ç‚¹èµæ•°ï¼Œä½†ç›®å‰ä¹Ÿæ— æ³•è·å–å¾®åšè§†é¢‘çš„æ’­æ”¾é‡ã€‚

å› æ­¤åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘è¿˜ä¿®æ”¹äº†æºç ä¸­é¡µé¢è§£æç›¸å…³çš„å†…å®¹ï¼Œæ¯”å¦‚è·å–å’Œè§£æè§†é¢‘ä¿¡æ¯çš„å‡½æ•°ã€ä¿®æ”¹å†™å…¥ç»“æœæ–‡ä»¶çš„è¡¨å¤´ï¼Œå¹¶ä¸”æ›´æ–°å†™å…¥æ–¹æ³•ï¼Œç¡®ä¿è¯¥é¡¹æ•°æ®è¢«å†™å…¥æ–‡ä»¶ã€‚

è¿™é‡Œå®¹æ˜“ç¿»è½¦çš„æ˜¯ç¬¬ä¸€æ­¥ï¼Œè§£å†³æ–¹æ³•æ˜¯ï¼šé€šè¿‡æ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼Œæ‰“å°å‡ºæŠ“å–çš„åŸå§‹æ•°æ®ï¼Œç¡®è®¤æ’­æ”¾é‡çš„å­—æ®µæ˜¯å¦å­˜åœ¨ã€åœ¨å“ªä¸ªå­—æ®µä¸­ã€‚æ‰“å°å‡º Weibo Info åï¼Œå¯ä»¥çœ‹åˆ°æ’­æ”¾é‡ play_count çš„ä¿¡æ¯æ˜¯åœ¨ page_info çš„ç»“æ„ä¸­ã€‚è¿™ä¸ªå­—æ®µçš„å€¼æ˜¯ã€Œ5 ä¸‡æ¬¡æ’­æ”¾ã€ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªæ•°å­—ã€‚ç›¸å…³è°ƒè¯•ä»£ç å¦‚ä¸‹ï¼š

```python
def get_video_url(self, weibo_info):
    """è·å–å¾®åšè§†é¢‘urlå’Œæ’­æ”¾é‡"""
    video_url = ""
    play_count = 0  ## æ–°å¢æ’­æ”¾é‡å˜é‡

    if weibo_info.get("page_info"):
        media_info = weibo_info["page_info"].get("urls") or weibo_info["page_info"].get("media_info")

        ## print("Weibo Info:", weibo_info)  
        ## print("Media Info:", media_info)  
        
        if media_info and weibo_info["page_info"].get("type") == "video":
            video_url = media_info.get("mp4_720p_mp4")

            ## ä» page_info ä¸­è·å–æ’­æ”¾é‡
            play_count_str = weibo_info["page_info"].get("play_count", "0æ¬¡æ’­æ”¾")
            ## æå–æ•°å­—éƒ¨åˆ†
            ## æŠŠå­—ç¬¦ä¸²è½¬æ¢ä¸ºæ•´æ•° play_count = int(play_count_str.replace("æ¬¡æ’­æ”¾", "").replace("ä¸‡", "0000").replace("ä¸‡æ¬¡æ’­æ”¾", "0000").replace("æ¬¡", ""))
            match = re.search(r'\\d+', play_count_str)
            play_count = int(match.group()) if match else 0  ## å¦‚æœæ‰¾åˆ°æ•°å­—ï¼Œåˆ™è½¬æ¢ä¸ºæ•´æ•°ï¼Œå¦åˆ™ä¸º 0

            print("Video URL:", video_url)  
            print("Play Count:", play_count)  
```

Weibo Spider æ˜¯æ ¹æ®å¾®åšç”¨æˆ· id è®¿é—®ä¸»é¡µå¹¶ä¾åºé€æ¡æå–å¾®åšæ•°æ®ï¼Œæœ€ç»ˆå­˜å‚¨åˆ° csv æ–‡ä»¶çš„çˆ¬è™«ç¨‹åºã€‚å®ƒæœ¬è´¨ä¸Šæ˜¯ä¸€ç§è½®æŸ¥ï¼ˆPollingï¼‰ï¼Œæ•°æ®æ›´æ–°çš„é¢‘ç‡å–å†³äºçˆ¬å–çš„é—´éš”æ—¶é—´ã€‚

æŒ‰ç…§ä¸€å¼€å§‹çš„éœ€æ±‚ï¼Œæˆ‘åªéœ€è¦è·å–å•æ¡å¾®åšçš„æ•°æ®ã€‚æœ¬æ¥çŠ¯æ‡’ä¸æƒ³ä»”ç»†çœ‹æ˜¯æ€ä¹ˆå®ç°çš„ï¼Œç›´æ¥ä» csv æ–‡ä»¶ä¸­ç­›é€‰å‡ºå¯¹åº”çš„å•æ¡å¾®åšå‡‘åˆç”¨æ¥ç€ï¼Œåæ¥è¿˜æ˜¯å¿å—ä¸äº†â€¦â€¦å› ä¸ºå¦‚æœè®¾å®šçš„å†…å®¹çˆ¬å–å‘¨æœŸæ¯”è¾ƒé•¿ï¼ŒåŠ ä¹‹è¯¥æœŸé—´è´¦å·å‘å¸ƒçš„å†…å®¹è¾ƒå¤šï¼Œè¿™ç§æ–¹æ³•ä¼šæ¯”è¾ƒæµªè´¹èµ„æºã€‚

å…¶å®å®ç°èµ·æ¥ä¹Ÿä¸éš¾ï¼Œç§»åŠ¨ç«¯çš„å¾®åšæ•°æ®æ¯”è¾ƒè§„æ•´ä¹Ÿä¸ä¼šæœ‰ç™»å½•é™åˆ¶ï¼Œè§£ææŠ“å–åˆ°çš„å†…å®¹å°±å¯ä»¥äº†ã€‚ç¨å¾®ä¸å¤ªé¡ºæ‰‹çš„ä¸€ç‚¹æ˜¯å•æ¡å¾®åš id çš„è·å–ï¼Œç½‘é¡µç«¯ç›´æ¥åˆ†äº«çš„çŸ­é“¾å¹¶ä¸å¸¦æœ‰å¾®åšå”¯ä¸€ idï¼Œå¿…é¡»ä»ç§»åŠ¨ç«¯åˆ†äº«å–å¾—ã€‚ç›¸å…³ç¤ºä¾‹ä»£ç å¦‚ä¸‹ï¼š

```python
#!/usr/bin/env python
## -*- coding: utf-8 -*-

import argparse
import requests
import json
from datetime import datetime
import logging
import urllib3

## ç¦ç”¨ SSL è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

def get_single_weibo(weibo_id, headers=None):
    """è·å–æŒ‡å®šIDçš„å•æ¡å¾®åšä¿¡æ¯"""
    if headers is None:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.111 Safari/537.36'
        }
    
    try:
        url = f"<https://m.weibo.cn/detail/{weibo_id}>"
        response = requests.get(url, headers=headers, verify=False)
        html = response.text
        html = html[html.find('"status":'):]
        html = html[:html.rfind('"call"')]
        html = html[:html.rfind(",")]
        html = "{" + html + "}"
        js = json.loads(html, strict=False)
        weibo_info = js.get("status")
        
        if weibo_info:
            ## æå–åŸºæœ¬ä¿¡æ¯
            weibo = {
                'id': weibo_info['id'],
                'screen_name': weibo_info['user']['screen_name'],
                'text': weibo_info['text'],
                'attitudes_count': weibo_info['attitudes_count'],
                'comments_count': weibo_info['comments_count'],
                'reposts_count': weibo_info['reposts_count'],
                'created_at': weibo_info['created_at']
            }
            
            ## è·å–è§†é¢‘ä¿¡æ¯
            if weibo_info.get("page_info"):
                page_info = weibo_info["page_info"]
                if page_info.get("type") == "video":
                    weibo['play_count'] = page_info.get("play_count", "0")
                    weibo['video_title'] = page_info.get("title", "")
            
            return weibo
            
        return None
            
    except Exception as e:
        logger.error(f"è·å–å¾®åšä¿¡æ¯å‡ºé”™: {e}")
        return None

def main():
    parser = argparse.ArgumentParser(description='è·å–å¾®åšæ•°æ®å¹¶è¾“å‡ºåˆ°å‘½ä»¤è¡Œ')
    parser.add_argument('--id', type=str, required=True, help='å¾®åšID')
    args = parser.parse_args()
    
    weibo_info = get_single_weibo(args.id)
    if weibo_info:
        ## è¾“å‡ºå¾®åšä¿¡æ¯åˆ°å‘½ä»¤è¡Œ
        print(f"ç”¨æˆ·: {weibo_info['screen_name']}")
        print(f"åˆ›å»ºæ—¶é—´: {weibo_info['created_at']}")
        print(f"å†…å®¹: {weibo_info['text']}")
        print(f"ç‚¹èµæ•°: {weibo_info['attitudes_count']}")
        print(f"è¯„è®ºæ•°: {weibo_info['comments_count']}")
        print(f"è½¬å‘æ•°: {weibo_info['reposts_count']}")
        if 'play_count' in weibo_info:
            print(f"æ’­æ”¾é‡: {weibo_info['play_count']}")
            print(f"è§†é¢‘æ ‡é¢˜: {weibo_info['video_title']}")
    else:
        logger.error("è·å–å¾®åšä¿¡æ¯å¤±è´¥")

if __name__ == "__main__":
    main()
```

è‡³æ­¤ï¼Œå’Œç®€ä¸­äº’ä¸è”ç½‘å¹³å°çš„æ–—æ™ºæ–—å‹‡ç°åœ¨æ‰åˆšåˆšå¼€å§‹ã€‚å®é™…ä¸Šä¸€å¼€å§‹ç§°ä¹‹ä¸ºåŠæˆå“çš„åŸå› åœ¨äºï¼Œå‰©ä¸‹çš„å¹³å°æˆ‘å¹¶æœªæ²¡æœ‰æˆåŠŸç”¨è¾ƒä¸ºç®€å•çš„æ–¹å¼è·å–åˆ°æ’­æ”¾æ•°æ®ã€‚

[å°çº¢ä¹¦å¼€æ”¾å¹³å°](https://open.xiaohongshu.com/home)åªæä¾›åº—é“ºç›¸å…³çš„ APIï¼Œå€’æ˜¯[æœ‰äººä½¿ç”¨ Appium+Mitmproxy+Fiddler+å¤œç¥æ¨¡æ‹Ÿå™¨](https://github.com/Big-Buffer/XiaohongshuSpider)å®ç°ï¼Œçœ‹èµ·æ¥æœ‰ç‚¹è¿‡äºéº»çƒ¦ã€‚Github ä¸Šè¿˜æœ‰ä¸ªé¡¹ç›® [xhs](https://github.com/ReaJason/xhs?tab=readme-ov-file) ä¼¼ä¹å®ç°äº†ï¼Œä½†ç›®å‰çš„å¯ç”¨æ€§æ— æ³•éªŒè¯ã€‚è€ƒè™‘åˆ°æœ€é‡è¦çš„æ’­æ”¾é‡æ•°æ®ï¼Œåœ¨å°çº¢ä¹¦ä¸Šå¹¶ä¸å…¬å¼€å¯è§ï¼Œè¿™æœ¬æ¥å°±ä»…é™å‘å¸ƒè€…æœ¬äººå¯ä»¥æŸ¥çœ‹ï¼Œéå…¬å¼€æ•°æ®æœ¬èº«è·å–éš¾åº¦ä¼šæ›´å¤§ä¸€äº›ã€‚

æŠ–éŸ³å¼€æ”¾å¹³å°æä¾›[æŸ¥è¯¢ç‰¹å®šè§†é¢‘æ•°æ®çš„ API](https://developer.open-douyin.com/docs/resource/zh-CN/dop/develop/openapi/video-management/douyin/search-video/video-data)ï¼Œåæ¶ˆæ¯æ˜¯ä¸ªäººèº«ä»½ä»…æ”¯æŒåˆ›å»ºå°æ¸¸æˆå’Œç›´æ’­å°ç©æ³•ï¼Œè¿™ä¸ªæ¥å£éœ€è¦ä¼ä¸šèº«ä»½è®¤è¯ï¼Œæ¥å¼€å¯ç§»åŠ¨/ç½‘ç«™åº”ç”¨çš„è§†é¢‘æƒé™ã€‚å¥½æ¶ˆæ¯æ˜¯ [Douyin_TikTok_Download_API](https://github.com/Evil0ctal/Douyin_TikTok_Download_API) æä¾›äº†ç±»ä¼¼çš„åŠŸèƒ½ ï¼Œåæ¶ˆæ¯ again æ˜¯å®ƒå¹¶æ²¡æœ‰æä¾›å•ä¸ªè§†é¢‘æ’­æ”¾ã€äº’åŠ¨æ•°æ®çš„æ¥å£ã€‚

å…¬ä¼—å·çš„[è·å–å›¾æ–‡ç¾¤å‘æ¯æ—¥æ•°æ®æ¥å£](https://developers.weixin.qq.com/doc/offiaccount/Analytics/Graphic_Analysis_Data_Interface.html)å¯ä»¥è·å–åˆ°å®æ—¶çš„é˜…è¯»æ•°æ®ï¼Œä½†éœ€è¦å…¬ä¼—å·ç®¡ç†å‘˜æƒé™å¼€é€šéªŒè¯ access_tokenï¼Œæˆ‘çš„æ“ä½œæƒé™ä¸å¤Ÿï¼Œæ­¤å¤–ç‚¹èµã€åœ¨çœ‹å’Œè½¬å‘ç­‰äº’åŠ¨æ•°æ®ä¹Ÿæ— æ³•è·å–ã€‚ç¬¬ä¸‰æ–¹å®ç°é€šå¸¸éœ€è¦é€šè¿‡ä»£ç†æŠ“åŒ…ï¼Œä½†å…³é”®å‚æ•°ä¹Ÿéœ€è¦æ‰‹åŠ¨è·å–ï¼Œå› ä¸º key ä¼šå®šæ—¶åˆ·æ–°â€¦â€¦è¯¦è§ [https://github.com/wnma3mz/wechat_articles_spiderã€‚åŒä¸ºè…¾è®¯ç³»çš„è§†é¢‘å·çŠ¶å†µä¹Ÿç±»ä¼¼ï¼Œä½œä¸ºéº»ç“œå’Œè…¾è®¯](https://github.com/wnma3mz/wechat_articles_spider%E3%80%82%E5%90%8C%E4%B8%BA%E8%85%BE%E8%AE%AF%E7%B3%BB%E7%9A%84%E8%A7%86%E9%A2%91%E5%8F%B7%E7%8A%B6%E5%86%B5%E4%B9%9F%E7%B1%BB%E4%BC%BC%EF%BC%8C%E4%BD%9C%E4%B8%BA%E9%BA%BB%E7%93%9C%E5%92%8C%E8%85%BE%E8%AE%AF) battle çš„æˆæœ¬è¿‡é«˜ï¼Œé‚æ”¾å¼ƒã€‚

ä½ çœ‹ï¼Œä¸–ä¸Šæ— éš¾äº‹ï¼Œåªè¦è‚¯æ”¾å¼ƒ(ã€‚æœ¬æƒ³å·ä¸ªæ‡’ä»¥é¡¹ç›®ä¸ºå•ä½è·å–å…¨å¹³å°çš„æ’­æ”¾é‡æ•°æ®ï¼Œç»“æœè½¬äº†ä¸€åœˆä¸‹æ¥å››å¤„æ’å¢™ã€‚äº‹å·²è‡³æ­¤ï¼Œè¿˜æ˜¯å…ˆæŠŠåŸºæœ¬æµç¨‹è·‘é€šï¼Œç»™è¿™ä»¶äº‹ç”»ä¸ªå¥å·ã€‚

### é£ä¹¦ WebHook

bilibiliã€YouTube å’Œå¾®åšçš„æ•°æ®è·å–å·²ç»è§£å†³ï¼Œä¸»è¦çš„é•¿è§†é¢‘å¹³å°å·¦å³ä¹Ÿå°±è¿™ä¿©(ä»¨)ï¼Œæ¥ä¸‹æ¥è§£å†³å®šæ—¶è½¬æ’­æ•°æ®çš„éœ€æ±‚ï¼Œå†æ‹†è§£å…¶å®æ˜¯ä¸¤ä¸ªé—®é¢˜â€”â€”ä¿¡æ¯ä¼ é€’å’Œå®šæ—¶ä»»åŠ¡ã€‚å¦‚æœæœ‰éœ€è¦ï¼Œè¿˜å¯ä»¥å¸¦ä¸Šä¸ªæ•°æ®å­˜å‚¨ï¼Œæ¯•ç«Ÿé˜¿ B åå°å¹¶ä¸æä¾›å›ºå®šå‘¨æœŸçš„æ•°æ®å¯¹æ¯”åŠŸèƒ½ã€‚

å…¬å¸ç”¨çš„ IM è½¯ä»¶æ˜¯é£ä¹¦ï¼Œå®ƒçš„è‡ªå®šä¹‰æœºå™¨äººæ”¯æŒ WebHookï¼Œå¯ä»¥å°†å…¶ä»–å¹³å°çš„æ¶ˆæ¯æ¨é€è‡³è¯¥ç¾¤ç»„ä¸­ï¼Œå®Œç¾çš„æé†’å·¥å…·ã€‚

> WebHook æ˜¯ä¸€ç§åŸºäº HTTP çš„å›è°ƒæœºåˆ¶ï¼Œå…è®¸ä¸€ä¸ªç³»ç»Ÿåœ¨ç‰¹å®šäº‹ä»¶å‘ç”Ÿæ—¶è‡ªåŠ¨å‘å¦ä¸€ä¸ªç³»ç»Ÿå‘é€å®æ—¶é€šçŸ¥ã€‚å½“è§¦å‘é¢„è®¾æ¡ä»¶æ—¶ï¼Œæºç³»ç»Ÿä¼šå°†ç›¸å…³æ•°æ®ä»¥ POST è¯·æ±‚çš„æ–¹å¼æ¨é€åˆ°ç›®æ ‡ç³»ç»Ÿçš„æŒ‡å®š URLï¼Œæ¥æ”¶æ–¹å¯ä»¥ç«‹å³å¤„ç†è¿™äº›ä¿¡æ¯ã€‚è¿™ç§æ–¹å¼ç±»ä¼¼äº " äº‹ä»¶é€šçŸ¥ "ï¼Œé¿å…äº†ä¼ ç»Ÿè½®è¯¢æ–¹å¼çš„ä½æ•ˆï¼Œå¹¿æ³›åº”ç”¨äºæ”¯ä»˜é€šçŸ¥ã€ä»£ç æ‰˜ç®¡å¹³å°çš„å˜æ›´æé†’ã€æ¶ˆæ¯æ¨é€ç­‰åœºæ™¯ï¼Œå®ç°äº†ä¸åŒç³»ç»Ÿé—´å¿«é€Ÿã€å®æ—¶çš„æ•°æ®äº¤äº’ã€‚

å¥½çš„ï¼Œæ˜¾ç„¶ä¸Šé¢è¿™ä¸ªè§£é‡Šå¤ªæ‰ä¹¦è¢‹äº†ã€‚ç®€å•æ¥è¯´ï¼Œåœ¨é£ä¹¦é‡Œè®¾å®šå¥½ä¸€ä¸ªè‡ªå®šä¹‰æœºå™¨äººï¼Œæˆ‘ä»¬ä¼šè·å¾—ä¸€ä¸ªé“¾æ¥ã€‚åˆ©ç”¨è¿™ä¸ªé“¾æ¥ä¼ è¾“æ•°æ®ï¼Œæœºå™¨äººå°±ä¼šåœ¨ç¾¤ç»„é‡Œå¼¹æ¶ˆæ¯äº†ï¼

è¿™æ ·æˆ‘å°±ä¸éœ€è¦â€œæ—¶ä¸æ—¶â€æˆ³å¼€è§†é¢‘çœ‹ä¸€çœ¼æ•°æ®ï¼Œç„¶åæ’­æŠ¥ç»™è€æ¿å¨˜äº†ï¼Œå¥½è€¶ï¼åŸºæœ¬çš„è®¾ç½®æµç¨‹ï¼Œå¯ä»¥å‚è§é£ä¹¦çš„[è‡ªå®šä¹‰æœºå™¨äººä½¿ç”¨æŒ‡å—](https://open.feishu.cn/document/client-docs/bot-v3/add-custom-bot?lang=zh-CN)ã€‚è·å–åˆ° WebHook URL åï¼Œåªéœ€è¦ç®€å•åœ°ä¿®æ”¹ä¸€ä¸‹è„šæœ¬ï¼Œå†™å¥½æ¶ˆæ¯å‘é€çš„æ ¼å¼å°±å¯ä»¥äº†ã€‚

å‘å¸ƒæ—¶é—´ä¹Ÿæ˜¯è¡¡é‡æ•°æ®è¡¨ç°çš„ç»´åº¦ä¹‹ä¸€ï¼Œå› æ­¤åŠ ä¸Šäº†è¿™ä¸ªæ•°æ®ï¼Œè¿˜é¡ºæ‰‹è®¡ç®—äº†äº’åŠ¨æ€»æ•°ã€‚ä¸‹ä¾‹ä¸º bilibiliï¼Œå…¶ä»–å¹³å°ç±»ä¼¼ï¼š

```python
import asyncio
import logging
import argparse
from datetime import datetime
from bilibili_api import video
import requests

## é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,  ## æ—¥å¿—çº§åˆ«
    format='%(asctime)s - %(levelname)s - %(message)s',  ## æ—¥å¿—æ ¼å¼
    handlers=[
        logging.FileHandler("video_monitor.log"),  ## æ—¥å¿—æ–‡ä»¶
        logging.StreamHandler()  ## æ§åˆ¶å°è¾“å‡º
    ]
)

## é£ä¹¦ Webhook URL
FEISHU_WEBHOOK_URL = '<https://open.feishu.cn/open-apis/bot/>'  ## è¾“å…¥é£ä¹¦ Bot url

## è®¾ç½®å‘½ä»¤è¡Œå‚æ•°
parser = argparse.ArgumentParser(description='Monitor Bilibili video.')
parser.add_argument('bv_id', type=str, help='The BV ID of the video to monitor.')
args = parser.parse_args()

async def fetch_video_data(bvid: str) -> None:
    ## å®ä¾‹åŒ– Video ç±»
    v = video.Video(bvid=bvid)  ## ä½¿ç”¨ä¼ å…¥çš„ BV å·
    ## è·å–ä¿¡æ¯
    info = await v.get_info()

    ## è·å–è§†é¢‘å‘å¸ƒæ—¶é—´
    pub_time_str = info['pubdate']  
    pub_time = datetime.fromtimestamp(pub_time_str)  

    ## è®¡ç®—å½“å‰æ—¶é—´å’Œè§†é¢‘å‘å¸ƒæ—¶é—´çš„å·®å€¼
    now = datetime.now()
    time_diff = now - pub_time

    ## è·å–ç»Ÿè®¡ä¿¡æ¯
    name = info['owner']['name']
    views = info['stat']['view']
    likes = info['stat']['like']
    replies = info['stat']['reply']
    coins = info['stat']['coin']
    favorites = info['stat']['favorite']
    shares = info['stat']['share']
    danmaku_count = info['stat']['danmaku']

    ## è®¡ç®—äº’åŠ¨æ€»æ•°ã€äº’åŠ¨å æ¯”å’ŒæŠ•å¸å æ¯”
    interaction_total = likes + replies + coins + favorites + shares + danmaku_count
    interaction_ratio = (interaction_total / views) * 100 if views > 0 else 0  ## é¿å…é™¤ä»¥é›¶
    coin_ratio = (coins / interaction_total) * 100 if interaction_total > 0 else 0  ## é¿å…é™¤ä»¥é›¶

    ## æ„å»ºé£ä¹¦å¡ç‰‡æ¶ˆæ¯æ ¼å¼
    card_message = {
        "msg_type": "interactive",
        "card": {
            "config": {
                "wide_screen_mode": True
            },
            "header": {
                "title": {
                    "tag": "plain_text",
                    "content": f"{info['owner']['name']} | {info['title']}"  ## ä¿®æ”¹æ¶ˆæ¯å¤´
                },
                "template": "orange"  ## è®¾ç½®æ ‡é¢˜ä¸»é¢˜é¢œè‰²
            },
            "elements": [
                {
                    "tag": "div",
                    "text": {
                        "tag": "lark_md",
                        "content": f"[è¯¥è§†é¢‘](<https://www.bilibili.com/video/{bvid}>)è·ä»Šå·²å‘å¸ƒ {time_diff.days} å¤© {time_diff.seconds // 3600} å°æ—¶ï¼Œå½“å‰ B ç«™æ’­æ”¾é‡ä¸º **{views / 10000:.1f} ä¸‡**ï¼Œ\\n\\näº’åŠ¨æ€»æ•°ä¸º **{interaction_total / 10000:.1f} ä¸‡**ï¼Œäº’åŠ¨å æ¯”ä¸º **{interaction_ratio:.2f}%**ï¼ŒæŠ•å¸å æ¯”ä¸º **{coin_ratio:.2f}%**ã€‚\\n\\nè¯¦ç»†æ•°æ® ğŸ‘‰ æ’­æ”¾é‡: {views}  äº’åŠ¨æ€»æ•°: {interaction_total} ç‚¹èµæ•°: {likes}  è¯„è®ºæ•°: {replies}  æŠ•å¸æ•°: {coins}  æ”¶è—æ•°: {favorites}  è½¬å‘æ•°: {shares}  å¼¹å¹•æ•°: {danmaku_count}"
                    }
                }
            ]
        }
    }

    ## å‘é€æ¶ˆæ¯åˆ°é£ä¹¦
    await send_to_feishu(card_message)

async def send_to_feishu(data):
    requests.post(FEISHU_WEBHOOK_URL, json=data)

## ä¸»å‡½æ•°
async def main():
    await fetch_video_data(args.bv_id)  ## ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°ä¸­çš„ BV ID

## æ‰§è¡Œä¸»å‡½æ•°
if __name__ == "__main__":
    asyncio.run(main())
```

å®é™…æ¥æ”¶åˆ°æ¶ˆæ¯çš„æ•ˆæœæ˜¯è¿™æ ·çš„ï¼š

![1737881422761.png](https://zyin-1309341307.cos.ap-nanjing.myqcloud.com/note/1737881422761.png)

å¦‚æœä½ åƒæˆ‘ä¸€æ ·è¦è¿è¥å¤šä¸ªçŸ©é˜µå·ï¼Œè¿˜å¯ä»¥é¡ºæ‰‹ä¿®æ”¹ä¸‹é¢œè‰²æ–¹ä¾¿è¾¨è¯†ï¼ŒåŠ ä¸Šä¸ªå˜é‡å³å¯ï¼š

```python
#å¦‚æœæ˜¯è´¦å·1ï¼Œåˆ™æ˜¯ç´«è‰²ï¼›è´¦å· 2 åˆ™æ˜¯ç²‰è‰²ï¼›é™¤äº†è¿™ä¿©ï¼Œé»˜è®¤æ˜¯æ©™è‰²ã€‚
template_color = "purple" if info['owner']['name'] == "è´¦å·å1" else "carmine" if info['owner']['name'] == "è´¦å·å2" else "orange"

#è®°å¾—æŠŠæ¶ˆæ¯æ ¼å¼é‡Œçš„ template ä¹Ÿæ”¹ä¸‹ã€‚
"template": template_color  ## è®¾ç½®æ ‡é¢˜ä¸»é¢˜é¢œè‰²
```

å¦‚æœå¸Œæœ›ä»¥ 7 å¤©ä¸ºå‘¨æœŸæ¨ªå‘å¯¹æ¯”å„ä¸ªè§†é¢‘çš„æ•°æ®è¡¨ç°ï¼Œé‚£è¿˜å¯ä»¥åŠ å…¥ä¸‹é¢è¿™æ®µä»£ç ï¼Œè¿™æ ·å®ƒå°±ä¼šåœ¨ç¬¬ä¸ƒå¤©ä¿å­˜å½“æ—¶çš„æ•°æ®è¿›å…¥ bilibili_7-Day.csv çš„æ–‡ä»¶ä¸­ã€‚

```python
## åœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ 
from pathlib import Path
import csv

## åœ¨ fetch_video_data å‡½æ•°å¼€å§‹å¤„æ·»åŠ æ•°æ®ç›®å½•è®¾ç½®
def ensure_data_dir():
    ## åœ¨è„šæœ¬æ‰€åœ¨ç›®å½•åˆ›å»º data æ–‡ä»¶å¤¹
    data_dir = Path(__file__).parent / 'data'
    data_dir.mkdir(exist_ok=True)
    return data_dir

## åœ¨ fetch_video_data å‡½æ•°ä¸­ä¿®æ”¹CSVç›¸å…³ä»£ç 
    ## æ£€æŸ¥æ˜¯å¦ä¸ºç¬¬7å¤©
    days_diff = time_diff.days
    if days_diff == 7:
        ## å‡†å¤‡CSVæ–‡ä»¶
        data_dir = ensure_data_dir()
        csv_file = data_dir / 'bilibili_7-Day.csv'
        file_exists = csv_file.exists()
        
        ## å‡†å¤‡è¦å†™å…¥çš„æ•°æ®
        headers = ['è§†é¢‘æ ‡é¢˜', 'å‘å¸ƒæ—¶é—´', 'å½“å‰æ—¶é—´', 'æ’­æ”¾é‡', 'äº’åŠ¨æ€»æ•°', 
                  'ç‚¹èµæ•°', 'è¯„è®ºæ•°', 'æŠ•å¸æ•°', 'æ”¶è—æ•°', 'è½¬å‘æ•°', 'å¼¹å¹•æ•°']
        row_data = [
            info['title'],
            pub_time.strftime('%Y-%m-%d %H:%M:%S'),
            now.strftime('%Y-%m-%d %H:%M:%S'),
            views,
            interaction_total,
            likes,
            replies,
            coins,
            favorites,
            shares,
            danmaku_count
        ]
        
        ## å†™å…¥CSVæ–‡ä»¶
        with open(csv_file, 'a', newline='', encoding='utf-8-sig') as f:
            writer = csv.writer(f)
            if not file_exists:
                writer.writerow(headers)
            writer.writerow(row_data)
            
        logging.info(f"å·²å°†ç¬¬7å¤©æ•°æ®å†™å…¥ {csv_file}: {info['title']}")
```

### å®šæ—¶æ‰§è¡Œè„šæœ¬ä»»åŠ¡

èƒ½æˆåŠŸå†™å…¥ç¬¬ 7 å¤©æ•°æ®çš„å‰ææ˜¯ï¼Œæˆ‘ä»¬éœ€è¦åœ¨ç¬¬ 7 å¤©çš„æ—¶å€™è¿è¡Œå®ƒï¼Œè¿™å°±æ¶‰åŠåˆ°å®šæ—¶ä»»åŠ¡äº†ã€‚

å¾ˆå¯æƒœæˆ‘å®¶æ²¡æœ‰è£…å®½å¸¦ï¼Œä¹Ÿæ²¡æœ‰å¯ä»¥ç©çš„å°ä¸»æœºä¹‹ç±»çš„ä¸œè¥¿ã€‚è€ƒè™‘åˆ°æˆ‘ä»¬è¿™ç§éšæ—¶ on call çš„å²—ï¼Œä¸ºäº†æ–¹ä¾¿è¿œæ§è®¿é—® NASï¼Œç”µè„‘å‡ ä¹ä¸å…³æœºâ€¦â€¦é‚£å°±ç›´æ¥ç”¨å…¬å¸ç”µè„‘æ¥è®¾ç½®å®šæ—¶ä»»åŠ¡å¥½äº†ã€‚

æœ€ç®€å•çš„å®ç°æ˜¯ Windows è‡ªå¸¦çš„ã€Œä»»åŠ¡è®¡åˆ’ç¨‹åºã€ï¼Œç†è®ºä¸Šè¿™ç§ç³»ç»Ÿå·¥å…·åº”è¯¥[é€æ­¥æŒ‰å¼•å¯¼æ“ä½œ](https://learn.microsoft.com/zh-cn/troubleshoot/windows-server/system-management-components/schedule-server-process)å°±å¯ä»¥å®ç°ï¼ŒGUI å°±åº”å½“è®©äººçœ‹åˆ°å°±æ˜ç™½å¯¹å—ï¼Ÿå¯æƒœè¿™ä¸ªä¸–ç•Œä¸Šï¼Œåº”ç„¶å’Œå®ç„¶æ˜¯ä¸¤å›äº‹ã€‚

å¸¸è§„çš„æ•™ç¨‹åªè¯´äº†â€å°†æ‰€éœ€è¦è¿è¡Œçš„è„šæœ¬è·¯å¾„å¡«å…¥å³å¯â€œï¼Œä½†å®ƒä¸€ç›´æ— æ³•æŒ‰é¢„æœŸè¿è¡Œå®šæ—¶ä»»åŠ¡ã€‚å‡ ç»å‘¨æŠ˜åç»ˆäºåœ¨æŸä¸ªè§’è½ï¼ˆä¸€ç¯‡åä¸ºã€Œ[windowsè®¾ç½®å®šæ—¶æ‰§è¡Œè„šæœ¬](https://www.cnblogs.com/sui776265233/p/13602893.html)ã€çš„æ–‡ç« ï¼‰é‡ŒæŸ¥åˆ°ï¼Œå…¶å®éœ€è¦åœ¨å¯åŠ¨ç¨‹åºçš„é‚£éƒ¨åˆ†ï¼Œå…ˆå¡«å…¥ Python.exe çš„ç»å¯¹è·¯å¾„ï¼Œå¹¶åœ¨å¯é€‰çš„ä¸¤ä¸ªå‚æ•°ä¸­ï¼Œå¡«å…¥ Python è„šæœ¬è·¯å¾„å’Œè§£é‡Šå™¨è·¯å¾„ã€‚

![1737881461733.png](https://zyin-1309341307.cos.ap-nanjing.myqcloud.com/note/1737881461733.png)

å°½ç®¡è¿™ä½[è¿é£è€Œæ¥çš„å°éš](https://www.cnblogs.com/sui776265233)åœ¨ 2021 å¹´åœæ­¢äº†åšå®¢çš„æ›´æ–°ï¼Œä½†è¿˜æ˜¯ç”±è¡·åœ°æ„Ÿè°¢ ta çš„æ–‡ç« è§£å†³äº†æˆ‘çš„å°é—®é¢˜ã€‚è¿™å°±æ˜¯æˆ‘ç°åœ¨ä¾æ—§æ›´å–œæ¬¢æ–‡å­—ã€æ›´å–œæ¬¢ç½‘é¡µï¼Œå¹¶ä¸”æ— æ¯”ç—›æ¨æ­»é“¾çš„åŸå› ã€‚

ä¸è¿‡æˆ‘ä¾æ—§æ— æ³•æ¥å—éœ€è¦ä¸ºæ¯æ¬¡çš„å®šæ—¶ä»»åŠ¡é€æ¬¡ç‚¹å‡»è¿™ä¹ˆå¤šæ¬¡é¼ æ ‡ï¼Œæˆ‘çš„è…•ç®¡ç»¼åˆå¾å¯¹æ­¤è¡¨ç¤ºå¼ºçƒˆçš„ä¸æ»¡ã€‚äºæ˜¯åˆè®© AI å†™äº†ä¸€æ®µä½¿ç”¨ Schtasks å‘½ä»¤è¡Œå®Œæˆæ“ä½œçš„å‘½ä»¤ï¼š

```python
C:\\Windows\\System32\\schtasks.exe /create /tn "æµ‹è¯•" `
    /tr "cmd.exe /c cd /d C:\\Users\\wl747\\AppData\\Local\\Programs\\Python\\Python313 && C:\\Users\\wl747\\AppData\\Local\\Programs\\Python\\Python313\\pythonw.exe G:\\zdh\\bili.py BVå·" `
    /sc HOURLY /mo 6 /sd (Get-Date).ToString("yyyy/MM/dd") /st (Get-Date).ToString("HH:mm") `
    /du 360 /ed (Get-Date).AddDays(16).ToString("yyyy/MM/dd") `
    /f /ru "SYSTEM"
```

å®ƒå¯ä»¥å®ç°æ¯ 6 å°æ—¶è¿è¡Œä¸€æ¬¡ Python è„šæœ¬çš„è®¡åˆ’ä»»åŠ¡ï¼ŒæŒç»­ 16 å¤©ã€‚è¿™é‡Œéœ€è¦æ³¨æ„ï¼Œæ¯æ¬¡çš„å®šæ—¶ä»»åŠ¡æœ€å¥½ä¸é‡åã€‚å¦‚æœä½ éœ€è¦æ›´è¯¦ç»†çš„è§£é‡Šä»¥ä¾¿ä¿®æ”¹è¿™æ®µå‘½ä»¤ï¼Œå¯ä»¥æˆ³[è¿™é‡Œè®© Monica ä¸ºæ‚¨æœåŠ¡](https://monica.im/share/chat?shareId=q4cNbhNWIcmox9wq):pã€‚

è‡³æ­¤ï¼Œçœ‹ä¼¼ç®€å•å®åˆ™å¹¶æ²¡é‚£ä¹ˆç®€å•çš„è½¬æ’­æ•°æ®éœ€æ±‚ï¼Œç®—æ˜¯å®Œæˆäº†ã€‚

## æ•°æ®æ±‡æ€»å½•å…¥

å½“æˆ‘å‘è€æ¿å¨˜è¡¨ç¤ºè¿™ä¸ª Bot å¯ä»¥å®ç°å®šæ—¶æ’­æŠ¥æ•°æ®æƒ…å†µï¼Œå¯ä»¥æŠŠå®ƒé…ç½®åˆ°ç¾¤èŠçš„æ—¶å€™ï¼Œæ–°çš„éœ€æ±‚åˆæ¥äº†ã€‚åŒç†å¯å¾—ï¼ŒAI å¹¶ä¸ä¼šè®©äººå¤±ä¸šï¼Œåªä¼šè®©é¢„æœŸå¯å®ç°çš„éœ€æ±‚è¶Šå˜è¶Šå¤šã€‚

å‡ºäºäº¤ä»˜è¾¾æ ‡çš„è€ƒè™‘ï¼Œå¥¹ä¾æ—§è¦æ±‚æˆ‘åœ¨æ¯å‘¨äº”æ›´æ–°ä¸€ä»½å…¨å¹³å°æ•°æ®çš„è¡¨å•ï¼ˆäº‹å®ä¸Šåªæœ‰ 4 ä¸ªå¹³å°ï¼Œè€Œä¸”æˆ‘å‘ç°å¥¹ä¸Šæ¬¡çœ‹è¿™ä¸ªæ–‡æ¡£å·²ç»æ˜¯ä¸¤å‘¨å‰äº†ğŸš¬ï¼‰ã€‚åŠ ä¸Šæœ¬èº«æ—¶éš” 7 å¤©å°±éœ€è¦æ”¶å½•çš„é•¿ã€çŸ­è§†é¢‘è¡¨å•ï¼Œä»¥åŠ 2025 å¹´ç»©æ•ˆæ ‡å‡†æ›´æ–°ä¹‹åå¯¹å†…éƒ¨å…¬å¼€çš„è§†é¢‘æ•°æ®è¡¨å•ï¼ˆæ˜¯çš„ï¼Œå¾ˆéš¾æƒ³è±¡è§†é¢‘å†…å®¹åˆ¶ä½œå›¢é˜Ÿåœ¨æ­¤ä¹‹å‰æ˜¯æ— æ³•çœ‹åˆ°å¹³å°éå…¬å¼€æ•°æ®çš„â€¦â€¦ï¼‰ã€‚å¦å¤–ï¼Œç”²æ–¹ä¹Ÿç»å¸¸æå‡ºéœ€è¦æ±‡æ€»å…¨å¹³å°æ•°æ®çš„éœ€æ±‚ã€‚

äºæ˜¯æˆ‘éœ€è¦é¢‘ç¹å¡«å†™çš„è¡¨å•ä»ä¸¤ä»½å˜æˆäº†äº”ä»½ï¼Œè¡¨å¤´é¡¹è¦æ±‚å„ä¸ç›¸åŒã€‚æ•°æ®æ±‡æ€»è¿™ä»¶äº‹ï¼Œä¹Ÿå˜æˆäº†è´¹æ—¶è´¹åŠ›ä¸”æ¯«æ— æˆå°±æ„Ÿçš„ Dirty Workã€‚æ²¡æœ‰äººå¯ä»¥å¿å—éœ€è¦èŠ±ä¸€ä¸ªå°æ—¶åªæ˜¯ä¸ºäº†å¡«ä¸€ä»½è¯¥æ­»çš„è¡¨æ ¼ï¼Œä¸ºæ­¤éœ€è¦è·³è½¬ 12 ä¸ªå¹³å°æ‰¾åˆ°å¯¹åº”è§†é¢‘ã€ä¸€é¡¹é¡¹ç¡®è®¤æ•°æ®ã€ä¾æ¬¡å¯¹æ¯”è¡¨å¤´å¡«å…¥å›ºå®šæ ¼å­é‡Œï¼Œå¦‚æ­¤é‡å¤æˆç™¾ä¸Šåƒæ¬¡ã€‚

è¿™å¤ªæ„šè ¢äº†ï¼Œä½†å¾ˆæ˜¾ç„¶ï¼Œå„å¹³å°çš„å°é—­æ€§å¹¶æ²¡æœ‰æä¾›è¶³å¤Ÿç®€å•å¥½ç”¨çš„æ¥å£è®©è¿™ç§çç¢äº‹æ¶ˆå¤±ï¼Œå½“ç„¶æœ‰æ›´å¤æ‚çš„æ–¹å¼å¯ä»¥å®ç°ï¼Œè¿™è®©é‚£äº›ç¤¾åª’ç®¡ç†å¹³å°å¾—ä»¥ç›ˆåˆ©ã€‚åªä¸è¿‡æœ¬éº»ç“œè¢«æ‹’ä¹‹é—¨å¤–ï¼Œå¥½æ¶ˆæ¯æ˜¯æˆ‘ä»¬ä¾æ—§å¯ä»¥æ›²çº¿æ•‘å›½ã€‚

å¤§å¤šæ•°ï¼ˆ7/12ï¼‰å¹³å°æä¾›äº†è¯¦ç»†æ•°æ®å¯¼å‡ºçš„åŠŸèƒ½ï¼Œè¿˜æœ‰ 2 ä¸ªï¼ˆYouTube å’Œå¾®åšï¼‰å¯ä»¥é€šè¿‡ä¸Šè¿°çš„è„šæœ¬è·å–åˆ°ï¼Œå‰©ä¸‹ 3 ä¸ªæ— å…³ç´§è¦çš„å¹³å°ï¼Œåªæœ‰ç”²æ–¹ä¼šéœ€è¦ï¼Œå› æ­¤æ‰‹åŠ¨æ”¶å½•ä¹Ÿæ˜¾å¾—ä¸é‚£ä¹ˆä¸å¯æ¥å—ã€‚é‚£ä¹ˆï¼Œå¯¼å‡º 7 ä¸ªå¹³å°çš„æ•°æ®å¹¶ç­›é€‰æ ‡é¢˜å…³é”®è¯ï¼ŒåŒæ—¶ç»™åˆ° YouTube å’Œå¾®åšçš„è§†é¢‘é“¾æ¥ï¼Œç†è®ºä¸Šæ˜¯èƒ½å®ç°ä¸€é”®æ±‡æ€» 9 ä¸ªå¹³å°çš„æ•°æ®çš„ã€‚

åªæ˜¯æ‰‹åŠ¨ä¸‹è½½ 7 ä¸ªå¹³å°çš„æ•°æ®å†æä¾› 2 ä¸ªé“¾æ¥ï¼Œæ˜¾ç„¶æ¯”ä¹‹å‰é€ä¸ªæ±‡æ€»é‚£ä¹ˆå¤šè¡¨é¡¹æ¥å¾—å¯ä»¥æ¥å—ã€‚äºæ˜¯å¯¹å¤–æ±‡æ€»æ•°æ®çš„ 1.0 ç‰ˆæœ¬éå¸¸ç®€å•ç²—æš´ï¼Œç­›é€‰å›ºå®šè·¯å¾„é‡Œçš„æ–‡ä»¶ï¼Œæ ¹æ®å¹³å°åæ‰¾åˆ°å¯¹åº”æ–‡ä»¶ï¼Œç„¶ååŒ¹é…å’Œæ£€ç´¢å…³é”®è¯ä¸€è‡´çš„è¡Œï¼Œå¤åˆ¶è¡¨å¤´å’Œè¯¥è¡Œæ•°æ®åˆ°æ–°æ–‡ä»¶ä¸­ã€‚

![1737881485152.png](https://zyin-1309341307.cos.ap-nanjing.myqcloud.com/note/1737881485152.png)

è‡³äºä¸ºä»€ä¹ˆåŒºåˆ†å‡ºäº† 1.0 ç‰ˆæœ¬ï¼Œå› ä¸ºæ€»æ˜¯ä¼šæœ‰æ–°çš„è¦æ±‚ï¼Œ[Scope Creep](https://en.wikipedia.org/wiki/Scope_creep) æ°¸è¿œæ­£ç¡®ï¼Œè¢«å›°ä½çš„åªæœ‰ç‰›é©¬ğŸš¬ã€‚æœ‰äº›ç”²æ–¹å¯¹è¡¨å¤´çš„è¦æ±‚æ˜¯æŒ‡å®šçš„ï¼Œäºæ˜¯ 2.0 ç‰ˆæœ¬ç”¨äº†æ›´é€šç”¨çš„åŒ¹é…æ–¹å¼ï¼Œä¹Ÿè®©è¾“å‡ºæ›´åŠ è§„æ•´ã€‚

æœ€ç»ˆçš„è¾“å‡ºå°†ä¼šæ˜¯ï¼š

![1737881509051.png](https://zyin-1309341307.cos.ap-nanjing.myqcloud.com/note/1737881509051.png)

å…·ä½“çš„å®ç°å¦‚ä¸‹ï¼š

```python
import os
import sys
import re
import pandas as pd
import traceback
from datetime import datetime
import urllib3
import yt_dlp
import requests
import json
import logging

## é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

## ç¦ç”¨ SSL è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

def format_youtube_date(date_str):
    try:
        if date_str and len(date_str) == 8:
            return f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}"
        return date_str
    except Exception as e:
        print(f"æ—¥æœŸæ ¼å¼è½¬æ¢é”™è¯¯: {e}")
        return date_str

def format_weibo_date(date_str):
    try:
        date_obj = datetime.strptime(date_str, "%a %b %d %H:%M:%S %z %Y")
        return date_obj.strftime("%Y-%m-%d %H:%M")
    except Exception as e:
        print(f"å¾®åšæ—¥æœŸæ ¼å¼è½¬æ¢é”™è¯¯: {e}")
        return date_str

def get_video_info(video_url):
    ydl_opts = {
        'quiet': True,
        'format': 'best',
        'noplaylist': True,
    }

    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info_dict = ydl.extract_info(video_url, download=False)
            title = info_dict.get('title', 'N/A')
            upload_date = format_youtube_date(info_dict.get('upload_date', 'N/A'))
            view_count = info_dict.get('view_count', 0)
            like_count = info_dict.get('like_count', 0)
            comment_count = info_dict.get('comment_count', 0) or 0

            return [
                'YouTube',
                title, 
                video_url, 
                upload_date, 
                str(view_count), 
                str(like_count), 
                str(comment_count)
            ]
    except Exception as e:
        print(f"è·å–YouTubeè§†é¢‘ä¿¡æ¯å¤±è´¥: {e}")
        return None

def convert_play_count(play_count_str):
    """
    å°†å¾®åšæ’­æ”¾é‡æ–‡å­—è½¬æ¢ä¸ºæ•°å€¼
    ä¾‹å¦‚ï¼š
    '10ä¸‡æ¬¡æ’­æ”¾' -> 100000
    '2åƒæ¬¡æ’­æ”¾' -> 2000
    '892æ¬¡æ’­æ”¾' -> 892
    """
    if not play_count_str:
        return 0
    
    play_count_str = str(play_count_str).replace('æ¬¡æ’­æ”¾', '').replace(' ', '')
    
    multipliers = {
        'ä¸‡': 10000,
        'åƒ': 1000,
    }
    
    for unit, multiplier in multipliers.items():
        if unit in play_count_str:
            try:
                number = float(play_count_str.replace(unit, ''))
                return int(number * multiplier)
            except ValueError:
                return 0
    
    try:
        return int(play_count_str)
    except ValueError:
        return 0

def get_single_weibo(weibo_id, headers=None):
    """è·å–æŒ‡å®šIDçš„å•æ¡å¾®åšä¿¡æ¯"""
    if headers is None:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.111 Safari/537.36'
        }
    
    try:
        url = f"<https://m.weibo.cn/detail/{weibo_id}>"
        response = requests.get(url, headers=headers, verify=False)
        html = response.text
        html = html[html.find('"status":'):]
        html = html[:html.rfind('"call"')]
        html = html[:html.rfind(",")]
        html = "{" + html + "}"
        js = json.loads(html, strict=False)
        weibo_info = js.get("status")
        
        if weibo_info:
            ## è·å–æ’­æ”¾é‡
            play_count = 0
            if weibo_info.get("page_info"):
                page_info = weibo_info["page_info"]
                if page_info.get("type") == "video":
                    play_count_str = page_info.get("play_count", "0")
                    play_count = convert_play_count(play_count_str)
            
            ## æ ¼å¼åŒ–è¿”å›æ•°æ®ï¼Œä¸åŸæœ‰è¾“å‡ºåˆ—ä¿æŒä¸€è‡´
            weibo = {
                'å¹³å°': 'å¾®åš',
                'æ ‡é¢˜': weibo_info['text'],
                'é“¾æ¥': f"<https://weibo.com/{weibo_info['user']['id']}/{weibo_info['bid']}>",
                'å‘å¸ƒæ—¶é—´': format_weibo_date(weibo_info['created_at']),
                'æ’­æ”¾é‡': str(play_count),
                'ç‚¹èµ': str(weibo_info['attitudes_count']),
                'è¯„è®º': str(weibo_info['comments_count']),
                'è½¬å‘': str(weibo_info['reposts_count'])
            }
            
            return list(weibo.values())
            
        return None
    
    except Exception as e:
        logger.error(f"è·å–å¾®åšä¿¡æ¯å‡ºé”™: {e}")
        return None

def extract_platform_name(filename):
    match = re.search(r'^([^\\-]+)', filename)
    return match.group(1) if match else filename

def match_column(df, target_columns):
    for col in df.columns:
        for target in target_columns.split('/'):
            if target in str(col):
                return col
    return None

def process_files(search_keyword, input_dir=None, sub_folder=None):
    ## å¦‚æœæ²¡æœ‰æä¾›è¾“å…¥ç›®å½•ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„
    if input_dir is None:
        today = datetime.now().strftime("%Y-%m-%d")
        input_dir = os.path.join('G:\\\\zdh\\\\platformdata', today)
        if sub_folder:
            input_dir = os.path.join(input_dir, sub_folder)
    
    ## å¹³å°å¤„ç†é¡ºåº
    platform_order = ['bilibili', 'æŠ–éŸ³', 'å°çº¢ä¹¦', 'å…¬ä¼—å·', 'è§†é¢‘å·', 'å¿«æ‰‹', 'å¤´æ¡å·']
    
    ## è¾“å‡ºåˆ—åŠå…¶å¯èƒ½çš„åˆ—å
    output_columns = {
        'å¹³å°': '',
        'æ ‡é¢˜': 'ä½œå“/æ ‡é¢˜/æè¿°',
        'é“¾æ¥': 'é“¾æ¥/url',
        'å‘å¸ƒæ—¶é—´': 'å‘å¸ƒæ—¶é—´/å‘è¡¨æ—¶é—´',
        'æ’­æ”¾é‡': 'æ’­æ”¾é‡/è§‚çœ‹é‡/æ€»é˜…è¯»æ¬¡æ•°',
        'ç‚¹èµ': 'ç‚¹èµ/å–œæ¬¢',
        'è¯„è®º': 'è¯„è®º',
        'è½¬å‘': 'è½¬å‘/è½¬å‘æ¬¡æ•°/åˆ†äº«',
        'æ”¶è—': 'æ”¶è—'
    }
    
    ## è¾“å‡ºç›®å½•å’Œæ–‡ä»¶å
    output_dir = 'G:\\\\zdh\\\\to_party_a'
    os.makedirs(output_dir, exist_ok=True)
    output_filename = f'output_{datetime.now().strftime("%Y%m%d%H%M%S")}.xlsx'
    output_file_path = os.path.join(output_dir, output_filename)
    
    ## è·å–æ‰€æœ‰è¾“å…¥æ–‡ä»¶ï¼ŒæŒ‰æŒ‡å®šé¡ºåºæ’åº
    input_files = [
        os.path.join(input_dir, f) 
        for f in os.listdir(input_dir)
        if f.endswith(('.csv', '.xlsx', '.xls', '.et')) 
        and not f.startswith('~$') 
        and not f.startswith('.')
    ]
    
    ## æŒ‰å¹³å°é¡ºåºæ’åº
    input_files.sort(key=lambda x: next((i for i, p in enumerate(platform_order) if p in os.path.basename(x)), len(platform_order)))
    
    ## åˆå§‹åŒ–è¾“å‡ºè¡Œ
    output_rows = [list(output_columns.keys())]
    
    for file_path in input_files:
        filename = os.path.basename(file_path)
        platform = extract_platform_name(filename)
        print(f"\\næ­£åœ¨å¤„ç†æ–‡ä»¶: {filename}")
        
        try:
            ## è¯»å–æ–‡ä»¶
            if file_path.endswith('.csv'):
                df = pd.read_csv(file_path, encoding='utf-8-sig')
            elif file_path.endswith('.xls'):
                df = pd.read_excel(file_path, engine='xlrd')
            else:
                if 'å°çº¢ä¹¦' in filename:
                    df = pd.read_excel(file_path, header=1)
                else:
                    df = pd.read_excel(file_path, engine='openpyxl')
            
            print(f"æ–‡ä»¶åˆ—å: {list(df.columns)}")
            print(f"æ–‡ä»¶è¡Œæ•°: {len(df)}")
            
            ## åœ¨ç¬¬ä¸€åˆ—ä¸­æœç´¢å…³é”®è¯
            matched_rows = df[df.iloc[:, 0].astype(str).str.contains(search_keyword, case=False, na=False)]
            
            if not matched_rows.empty:
                print(f"æ‰¾åˆ° {len(matched_rows)} è¡ŒåŒ¹é…æ•°æ®")
                
                for _, row in matched_rows.iterrows():
                    ## åˆ›å»ºæ–°è¡Œ
                    new_row = [platform]
                    
                    ## åŒ¹é…å…¶ä»–åˆ—
                    for col_name, possible_names in list(output_columns.items())[1:]:
                        if possible_names:
                            matched_col = match_column(df, possible_names)
                            value = row[matched_col] if matched_col else ''
                            new_row.append(str(value))
                        else:
                            new_row.append('')
                    
                    output_rows.append(new_row)
            else:
                print(f"æ–‡ä»¶ {filename} æœªæ‰¾åˆ°åŒ¹é…é¡¹")
        
        except Exception as e:
            print(f"å¤„ç†æ–‡ä»¶ {filename} æ—¶å‡ºé”™: {e}")
            traceback.print_exc()
    
    ## è¯¢é—®å¾®åšå’Œ YouTube é“¾æ¥
    print("\\nè¯·è¾“å…¥å¾®åšé“¾æ¥ï¼ˆä»¥ç©ºæ ¼åˆ†éš”ï¼Œæ²¡æœ‰åˆ™ç›´æ¥å›è½¦ï¼‰:")
    weibo_links = input().split()
    
    for link in weibo_links:
        weibo_id = link.split('/')[-1]
        weibo_data = get_single_weibo(weibo_id)
        if weibo_data:
            output_rows.append(weibo_data)
    
    print("\\nè¯·è¾“å…¥ YouTube é“¾æ¥ï¼ˆä»¥ç©ºæ ¼åˆ†éš”ï¼Œæ²¡æœ‰åˆ™ç›´æ¥å›è½¦ï¼‰:")
    youtube_links = input().split()
    
    for link in youtube_links:
        youtube_data = get_video_info(link)
        if youtube_data:
            output_rows.append(youtube_data)
    
    ## ä¿å­˜è¾“å‡ºæ–‡ä»¶
    output_df = pd.DataFrame(output_rows[1:], columns=output_rows[0])
    output_df.to_excel(output_file_path, index=False)
    print(f"\\nåŒ¹é…ç»“æœå·²ä¿å­˜åˆ°: {output_file_path}")

## ä¸»ç¨‹åºå…¥å£
if __name__ == '__main__':
    ## æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python è„šæœ¬.py <æœç´¢å…³é”®è¯> [å­æ–‡ä»¶å¤¹]")
        sys.exit(1)
    
    ## è·å–å‘½ä»¤è¡Œå‚æ•°
    search_keyword = sys.argv[1]
    sub_folder = sys.argv[2] if len(sys.argv) > 2 else None
    
    ## è°ƒç”¨å¤„ç†å‡½æ•°
    process_files(search_keyword, sub_folder=sub_folder)
```

å¦‚æœéœ€è¦å¢åˆ è¾“å‡ºä¸­çš„åˆ—ï¼Œåªéœ€è¦ä¿®æ”¹è¿™é‡Œçš„ä»£ç ï¼š

```python
    ## è¾“å‡ºåˆ—åŠå…¶å¯èƒ½çš„åˆ—å
    output_columns = {
        'å¹³å°': '',
        'æ ‡é¢˜': 'ä½œå“/æ ‡é¢˜/æè¿°',
        'é“¾æ¥': 'é“¾æ¥/url',
        'å‘å¸ƒæ—¶é—´': 'å‘å¸ƒæ—¶é—´/å‘è¡¨æ—¶é—´',
        'æ’­æ”¾é‡': 'æ’­æ”¾é‡/è§‚çœ‹é‡/æ€»é˜…è¯»æ¬¡æ•°',
        'ç‚¹èµ': 'ç‚¹èµ/å–œæ¬¢',
        'è¯„è®º': 'è¯„è®º',
        'è½¬å‘': 'è½¬å‘/è½¬å‘æ¬¡æ•°/åˆ†äº«',
        'æ”¶è—': 'æ”¶è—'
    }
```

å†’å·å‰æ˜¯è¾“å‡ºçš„åˆ—åï¼Œå†’å·åæ˜¯è¾“å…¥è¡¨ä¸­æ”¹æ•°å€¼é¡¹å¯èƒ½å¯¹åº”çš„åˆ—åï¼Œè®°å¾—æ³¨æ„é€—å·ã€‚

é™¤äº†ç»™ç”²æ–¹çš„å…¨å¹³å°æ±‡æ€»ä¹‹å¤–ï¼Œå†…éƒ¨è¦å¡«çš„è¡¨å•åªæ˜¯åŒºåˆ†é•¿çŸ­è§†é¢‘ï¼Œéœ€è¦æŠŠä¸åŒå¹³å°çš„æ•°æ®å¯¹åº”èµ·æ¥ï¼Œå®ç°ä¹Ÿæ˜¯ç±»ä¼¼çš„ï¼Œä»¥çŸ­è§†é¢‘å¹³å°çš„æ±‡æ€»ä¸ºä¾‹ï¼š

```python
import os
import pandas as pd
import glob
from datetime import datetime

def process_files(search_keyword, input_dir=None, sub_folder=None):
    ## è¾“å‡ºè·¯å¾„å’Œæ–‡ä»¶å
    output_dir = r'G:\\zdh\\data'
    os.makedirs(output_dir, exist_ok=True)  ## ç¡®ä¿ç›®å½•å­˜åœ¨

    ## å¦‚æœæ²¡æœ‰æä¾›è¾“å…¥ç›®å½•ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„
    if input_dir is None:
        today = datetime.now().strftime("%Y-%m-%d")
        input_dir = os.path.join('G:\\\\zdh\\\\platformdata', today)
        if sub_folder:
            input_dir = os.path.join(input_dir, sub_folder)

    ## è¾“å‡ºæ–‡ä»¶
    output_file = os.path.join(output_dir, f'Douyin_Daily.xlsx')
    
    ## åˆ›å»ºæˆ–è¯»å–è¾“å‡ºæ–‡ä»¶
    try:
        df_output = pd.read_excel(output_file)
    except FileNotFoundError:
        ## å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºä¸€ä¸ªå¸¦æœ‰é¢„å®šä¹‰åˆ—çš„ç©ºDataFrame
        columns = [
            'ä½œå“åç§°', 'å‘å¸ƒæ—¶é—´', 'ä½“è£', 'å®¡æ ¸çŠ¶æ€', 'æ’­æ”¾é‡', 'å®Œæ’­ç‡', '5så®Œæ’­ç‡', 
            'å°é¢ç‚¹å‡»ç‡', '2sè·³å‡ºç‡', 'å¹³å‡æ’­æ”¾æ—¶é•¿', 'ç‚¹èµé‡', 'åˆ†äº«é‡', 'è¯„è®ºé‡', 
            'æ”¶è—é‡', 'ä¸»é¡µè®¿é—®é‡', 'ç²‰ä¸å¢é‡', 
            'å°çº¢ä¹¦-è§‚çœ‹é‡', 'å°çº¢ä¹¦-ç‚¹èµ', 'å°çº¢ä¹¦-æ¶¨ç²‰',
            'å¿«æ‰‹-æ’­æ”¾é‡', 'å¿«æ‰‹-ç‚¹èµé‡', 'å¿«æ‰‹-æ¶¨ç²‰é‡',
            'è§†é¢‘å·-æ’­æ”¾é‡', 
            'bilibili2-æ’­æ”¾é‡', 'bilibili2-æ¶¨ç²‰é‡'
        ]
        df_output = pd.DataFrame(columns=columns)

    ## æŒ‰é¡ºåºå¤„ç†ä¸åŒå¹³å°æ–‡ä»¶
    platforms = [
        {'name': 'æŠ–éŸ³', 'filename': '*æŠ–éŸ³*.xlsx', 'search_column': 0, 'header': 0, 'data_columns': [
            'ä½œå“åç§°', 'å‘å¸ƒæ—¶é—´', 'ä½“è£', 'å®¡æ ¸çŠ¶æ€', 'æ’­æ”¾é‡', 'å®Œæ’­ç‡', '5så®Œæ’­ç‡', 
            'å°é¢ç‚¹å‡»ç‡', '2sè·³å‡ºç‡', 'å¹³å‡æ’­æ”¾æ—¶é•¿', 'ç‚¹èµé‡', 'åˆ†äº«é‡', 'è¯„è®ºé‡', 
            'æ”¶è—é‡', 'ä¸»é¡µè®¿é—®é‡', 'ç²‰ä¸å¢é‡'
        ]},
        {'name': 'å°çº¢ä¹¦', 'filename': '*å°çº¢ä¹¦*.xlsx', 'search_column': 0, 'header': 1, 'data_columns': [
            {'column': 'å°çº¢ä¹¦-è§‚çœ‹é‡', 'source_column': 'è§‚çœ‹é‡'},
            {'column': 'å°çº¢ä¹¦-ç‚¹èµ', 'source_column': 'ç‚¹èµ'},
            {'column': 'å°çº¢ä¹¦-æ¶¨ç²‰', 'source_column': 'æ¶¨ç²‰'}
        ]},
        {'name': 'å¿«æ‰‹', 'filename': '*å¿«æ‰‹*.xlsx', 'search_column': 0, 'header': 0, 'data_columns': [
            {'column': 'å¿«æ‰‹-æ’­æ”¾é‡', 'source_column': 'æ’­æ”¾é‡'},
            {'column': 'å¿«æ‰‹-ç‚¹èµé‡', 'source_column': 'ç‚¹èµé‡'},
            {'column': 'å¿«æ‰‹-æ¶¨ç²‰é‡', 'source_column': 'æ¶¨ç²‰é‡'}
        ]},
        {'name': 'è§†é¢‘å·', 'filename': ['*è§†é¢‘å·*.csv', '*è§†é¢‘å·*.xlsx'], 'search_column': 0, 'header': 0, 'data_columns': [
            {'column': 'è§†é¢‘å·-æ’­æ”¾é‡', 'source_column': 'æ’­æ”¾é‡'}
        ]},
        {'name': 'bilibili2', 'filename': ['*bilibili2*.csv', '*bilibili*.xlsx'], 'search_column': 0, 'header': 0, 'data_columns': [
            {'column': 'bilibili2-æ’­æ”¾é‡', 'source_column': 'æ’­æ”¾é‡'},
            {'column': 'bilibili2-æ¶¨ç²‰é‡', 'source_column': 'æ¶¨ç²‰é‡'}
        ]}
    ]

    ## åˆ›å»ºä¸€ä¸ªæ–°çš„ç©ºè¡Œç”¨äºå­˜å‚¨æ•°æ®
    new_row = pd.DataFrame(columns=df_output.columns)

    for platform in platforms:
        ## å¤„ç†å¯èƒ½çš„å¤šä¸ªæ–‡ä»¶åæ¨¡å¼
        filenames = platform['filename'] if isinstance(platform['filename'], list) else [platform['filename']]
        
        matched_file = None
        for filename in filenames:
            search_pattern = os.path.join(input_dir, filename)
            files = [f for f in glob.glob(search_pattern) if not os.path.basename(f).startswith('~$')]
            
            if files:
                matched_file = files[0]
                break
        
        if matched_file:
            try:
                ## æ ¹æ®æ–‡ä»¶ç±»å‹è¯»å–
                if matched_file.endswith('.xlsx'):
                    df = pd.read_excel(matched_file, header=platform['header'])
                elif matched_file.endswith('.csv'):
                    df = pd.read_csv(matched_file, encoding='utf-8', header=platform['header'])
            except Exception as e:
                print(f"è¯»å–æ–‡ä»¶ {matched_file} æ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")
                continue
            
            ## æœç´¢å…³é”®è¯
            try:
                matched_rows = df[df.iloc[:, platform['search_column']].str.contains(search_keyword, na=False)]
            except:
                matched_rows = df[df.apply(lambda row: row.astype(str).str.contains(search_keyword).any(), axis=1)]
            
            if not matched_rows.empty:
                row = matched_rows.iloc[0]
                
                ## æ ¹æ®å¹³å°ç‰¹å®šåˆ—åæå–æ•°æ®
                for col_info in platform['data_columns']:
                    if isinstance(col_info, dict):
                        source_column = col_info['source_column']
                        if source_column in df.columns:
                            new_row.loc[0, col_info['column']] = row[source_column]
                    else:
                        if col_info in df.columns:
                            col_index = df.columns.get_loc(col_info)
                            new_row.loc[0, col_info] = row.iloc[col_index]

    ## å¦‚æœæ‰¾åˆ°äº†æ•°æ®ï¼Œæ·»åŠ åˆ°è¾“å‡ºDataFrame
    if not new_row.empty and not new_row.loc[0].isnull().all():
        df_output = pd.concat([df_output, new_row], ignore_index=True)

    ## ä¿å­˜ç»“æœ
    df_output.to_excel(output_file, index=False)
    print(f"æ•°æ®å¤„ç†å®Œæˆï¼Œç»“æœå·²ä¿å­˜åˆ° {output_file}")
    return df_output

## ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    keyword = input("è¯·è¾“å…¥è¦æ£€ç´¢çš„å…³é”®è¯ï¼š")
    result = process_files(keyword)
    print(result)

```

## è¯„è®ºåŒºç›‘æµ‹

å¥½çš„ï¼Œå¦‚æœä½ çœ‹åˆ°è¿™é‡Œï¼Œä¼°è®¡å·²ç»å¿˜è®°æˆ‘ä¸€å¼€å§‹è¿˜æœ‰ä¸ªéœ€æ±‚æ˜¯ç›‘æµ‹è¯„è®ºæ¥ç€ã€‚åªæ˜¯ç­›é€‰è¯„è®ºåŒºå¹¶è½¬æ’­å€’æ˜¯ä¸éš¾ï¼Œæ„Ÿè°¢ [bilibili-api](https://github.com/Nemo2011/bilibili-api)ã€‚

ç›®å‰çš„è¿›åº¦æ˜¯å·²ç»å¯ä»¥è¯»å–åˆ°æ‰€æœ‰çš„è¯„è®ºï¼ˆåŒ…æ‹¬å‰¯æ¥¼ï¼‰ä¿å­˜åˆ°è¡¨æ ¼ï¼Œè¿˜åŠ äº†ç®€å•çš„ç­›é€‰è¯ï¼Œç­›é€‰å‡ºçš„è¯„è®ºå¯ä»¥é€šè¿‡å¸¦æœ‰ rpid çš„ç›´é“¾è·³è½¬å¤„ç†ï¼Œå†åŠ ä¸ª WebHook åŸºæœ¬èƒ½å‡‘åˆç”¨ï¼Œä¸è¿‡ä¸€ç›´æ²¡ç©ºæ‘¸é±¼æŠŠå®ƒåŠ ä¸Šâ€¦â€¦ç„¶åå°±æ”¾å‡äº†ï¼

è¿™ä¸ªç‰ˆæœ¬çš„ç¼ºç‚¹æ˜¯å¦‚æœå®šæ—¶ä»»åŠ¡è®¾å¾—æ¯”è¾ƒç´§å‡‘ï¼ŒIP ä¼šæš‚æ—¶è¢«å°ç¦æ— æ³• workï¼Œè¿™ä¸ªåº”è¯¥å¯ä»¥è®¾ç½®ä»£ç†ç»•è¿‡ã€‚

ç°åœ¨ã€Œè®¾ç½®å…³é”®è¯ç­›é€‰ -> ç»™ç›´é“¾è·³è½¬åˆ é™¤ã€æ¯”èµ·ä¹‹å‰ã€Œé€æ¡ç¿»è¯„è®º -> å®šå‘åˆ é™¤ã€æ¥å¾—æ–¹ä¾¿ï¼Œä¸è¿‡ç†è®ºä¸Šè¿˜å¯ä»¥åœ¨é£ä¹¦æ¶ˆæ¯[åŠ ä¸ªäº¤äº’](https://open.feishu.cn/document/uAjLw4CM/ukzMukzMukzM/feishu-cards/configuring-card-interactions)ï¼Œç»“åˆ [async def delete()](https://nemo2011.github.io/bilibili-api/#/modules/comment?id=async-def-delete) å°±å¯ä»¥ç›´æ¥ä¸€é”®åˆ é™¤ï¼Œä¸ç”¨äºŒæ¬¡è·³è½¬ç½‘é¡µã€‚

æ˜¯çš„ï¼Œè¿™é‡Œåˆè¦æœ‰ä½†æ˜¯äº†ï¼Œè´¦å·ä¼šéœ€è¦åœ¨æµè§ˆå™¨é•¿æœŸç™»å½•è´¦æˆ·ä»¥ä¾¿æŠ•ç¨¿ï¼Œè¿™æ ·ä¼šå¯¼è‡´ Cookies è¢«åˆ·æ–°â€¦â€¦ã€‚æ€»ä¹‹ï¼Œä»¥ä¸‹æ˜¯å†å‡‘åˆä¸€ä¸‹çš„ç‰ˆæœ¬ï¼š

```python
from bilibili_api import comment, Credential
import asyncio
import json
import pandas as pd
from datetime import datetime, timedelta
import os
import sys
import logging
import argparse

## é…ç½®æ—¥å¿—
def setup_logging(bvid):
    log_dir = os.path.join(r'G:\\zdh\\data\\comments', bvid)
    os.makedirs(log_dir, exist_ok=True)
    
    log_file = os.path.join(log_dir, 'bilibili_comment_crawler.log')
    logging.basicConfig(
        level=logging.INFO, 
        format='%(asctime)s - %(levelname)s: %(message)s',
        filename=log_file,
        filemode='a'
    )

## å®šä¹‰æ—¶é—´è®°å½•æ–‡ä»¶è·¯å¾„
def get_last_run_file(bvid):
    return os.path.join(r'G:\\zdh\\data\\comments', bvid, 'last_run_time.txt')

def read_last_run_time(bvid):
    """è¯»å–ä¸Šæ¬¡è¿è¡Œæ—¶é—´"""
    last_run_file = get_last_run_file(bvid)
    if os.path.exists(last_run_file):
        with open(last_run_file, 'r') as f:
            lines = f.readlines()
            ## å¦‚æœæ–‡ä»¶ä¸ä¸ºç©ºï¼Œè¿”å›æœ€åä¸€è¡Œçš„æ—¶é—´æˆ³
            return int(lines[-1].split()[0]) if lines else 0
    return 0  ## å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¿”å›0è¡¨ç¤ºè·å–æ‰€æœ‰è¯„è®º

def write_last_run_time(bvid, timestamp):
    """å†™å…¥æœ¬æ¬¡è¿è¡Œæ—¶é—´"""
    last_run_file = get_last_run_file(bvid)
    ## è½¬æ¢æ—¶é—´æˆ³ä¸ºå¯è¯»æ ¼å¼
    readable_time = datetime.fromtimestamp(timestamp).strftime('%Y/%m/%d %H:%M')
    
    with open(last_run_file, 'a') as f:
        ## å†™å…¥æ—¶é—´æˆ³å’Œå¯è¯»æ—¶é—´
        f.write(f"{timestamp} ## {readable_time}\\n")

def flatten_comment(comment, bvid):
    """å±•å¹³å•ä¸ªè¯„è®º"""
    try:
        rpid = comment.get("rpid", 0)
        flattened_comment = {
            "uname": comment["member"]["uname"],
            "message": comment["content"]["message"],
            "like": comment.get("like", 0),
            "ctime": comment["ctime"],
            "ip_location": comment.get('reply_control', {}).get('location', 'æœªçŸ¥'),
            "rpid": rpid,
            "comment_url": f"<https://www.bilibili.com/video/{bvid}/#reply{rpid}>"
        }
        return flattened_comment
    except Exception as e:
        logging.error(f"è§£æè¯„è®ºæ—¶å‡ºé”™: {e}")
        return None

def extract_comments(comments, bvid, last_run_time):
    """
    é€’å½’æå–è¯„è®ºï¼Œä»…ä¿ç•™æŒ‡å®šæ—¶é—´åçš„è¯„è®º
    
    :param comments: è¯„è®ºåˆ—è¡¨
    :param bvid: è§†é¢‘ID
    :param last_run_time: ä¸Šæ¬¡è¿è¡Œçš„æ—¶é—´æˆ³
    :return: è¿‡æ»¤åçš„è¯„è®ºåˆ—è¡¨
    """
    all_comments = []
    for comment in comments:
        ## æ£€æŸ¥è¯„è®ºæ—¶é—´æ˜¯å¦åœ¨ä¸Šæ¬¡è¿è¡Œä¹‹å
        if comment["ctime"] > last_run_time:
            flattened = flatten_comment(comment, bvid)
            if flattened:
                all_comments.append(flattened)
        
        ## é€’å½’å¤„ç†å­è¯„è®º
        if "replies" in comment and comment["replies"]:
            ## é€’å½’æ—¶ä¼ å…¥ last_run_time
            child_comments = extract_comments(comment["replies"], bvid, last_run_time)
            all_comments.extend(child_comments)
    
    return all_comments

async def get_new_comments(bvid, last_run_time):
    """è·å–è§†é¢‘çš„æ–°è¯„è®º"""
    comments = []
    page = 1
    
    while True:
        try:
            c = await comment.get_comments(
                bvid, 
                comment.CommentResourceType.VIDEO, 
                page,
                credential=credential
            )
            
            replies = c.get('replies', [])
            if not replies:
                break
            
            ## æ£€æŸ¥å½“å‰é¡µæ˜¯å¦è¿˜æœ‰æ–°çš„è¯„è®º
            new_comments = [r for r in replies if r["ctime"] > last_run_time]
            comments.extend(new_comments)
            
            ## å¦‚æœæ²¡æœ‰æ–°è¯„è®ºæˆ–å·²ç»åˆ°æœ€åä¸€é¡µï¼Œé€€å‡º
            if not new_comments or page > c['page']['count'] // c['page']['size'] + 1:
                break
            
            page += 1
        
        except Exception as e:
            logging.error(f"è·å–è¯„è®ºæ—¶å‡ºé”™: {e}")
            break
    
    return comments

def append_to_excel(new_df, bvid):
    """
    è¿½åŠ æ–°æ•°æ®åˆ°ç°æœ‰Excelæ–‡ä»¶
    å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»ºæ–°æ–‡ä»¶
    """
    filename = os.path.join(r'G:\\zdh\\data\\comments', bvid, f'{bvid}_comments.xlsx')
    
    try:
        ## å¦‚æœæ–‡ä»¶å­˜åœ¨ï¼Œè¯»å–ç°æœ‰æ•°æ®
        if os.path.exists(filename):
            existing_df = pd.read_excel(filename)
            
            ## å»é‡
            combined_df = pd.concat([existing_df, new_df]).drop_duplicates(subset=['rpid'])
            combined_df.to_excel(filename, index=False)
        else:
            ## å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œç›´æ¥ä¿å­˜
            new_df.to_excel(filename, index=False)
        
        logging.info(f"æ•°æ®å·²æˆåŠŸä¿å­˜åˆ° {filename}")
    except Exception as e:
        logging.error(f"ä¿å­˜Excelæ–‡ä»¶æ—¶å‡ºé”™: {e}")

async def main(bvid):
    ## è®¾ç½®æ—¥å¿—
    setup_logging(bvid)
    
    try:
        ## è¯»å–ä¸Šæ¬¡è¿è¡Œæ—¶é—´
        last_run_time = read_last_run_time(bvid)
        logging.info(f"ä¸Šæ¬¡è¿è¡Œæ—¶é—´: {last_run_time}")
        
        ## è·å–æ–°è¯„è®º
        new_video_comments = await get_new_comments(bvid, last_run_time)
        
        ## å±•å¹³å¹¶æå–æ–°è¯„è®º
        flattened_comments = extract_comments(new_video_comments, bvid, last_run_time)
        
        ## æ‰“å°æ€»æ–°è¯„è®ºæ•°
        logging.info(f"å…±è·å–åˆ° {len(flattened_comments)} æ¡æ–°è¯„è®º")
        
        ## ç­›é€‰åŒ…å«å…³é”®è¯çš„è¯„è®º
        filtered_comments = [
            comment for comment in flattened_comments 
            if any(keyword in comment['message'] for keyword in FILTER_KEYWORDS)
        ]
        
        ## è®°å½•å…³é”®è¯è¯„è®º
        logging.info(f"åŒ…å«å…³é”®è¯çš„è¯„è®ºå…± {len(filtered_comments)} æ¡")
        
        ## è½¬æ¢ä¸º DataFrame
        df = pd.DataFrame(flattened_comments)
        
        ## å¯¼å‡ºåˆ° xlsx æ–‡ä»¶ï¼Œä½¿ç”¨è¿½åŠ æ¨¡å¼
        append_to_excel(df, bvid)
        
        ## è®°å½•æœ¬æ¬¡è¿è¡Œæ—¶é—´
        current_timestamp = int(datetime.now().timestamp())
        write_last_run_time(bvid, current_timestamp)
        logging.info(f"æœ¬æ¬¡è¿è¡Œæ—¶é—´å·²è®°å½•: {current_timestamp}")
        
    except Exception as e:
        logging.error(f"è„šæœ¬æ‰§è¡Œå‡ºé”™: {e}", exc_info=True)

## æ·»åŠ ä¾èµ–æ£€æŸ¥
try:
    import bilibili_api
    import pandas as pd
except ImportError as e:
    print(f"ç¼ºå°‘å¿…è¦ä¾èµ–: {e}")
    print("è¯·è¿è¡Œ pip install bilibili-api-python pandas openpyxl")
    sys.exit(1)

if __name__ == "__main__":
    ## è®¾ç½®å‘½ä»¤è¡Œå‚æ•°è§£æ
    parser = argparse.ArgumentParser(description='bilibiliè¯„è®ºçˆ¬å–è„šæœ¬')
    parser.add_argument('bvid', help='è¦çˆ¬å–è¯„è®ºçš„è§†é¢‘BVå·')
    
    ## è§£æå‚æ•°
    args = parser.parse_args()
    
    ## å®ä¾‹åŒ– Credential
    credential = Credential(
        sessdata="your_sessdata",
        bili_jct="your_bili_jct",
        buvid3="your_buvid3",
        dedeuserid="your_dedeuserid",
        ac_time_value="your_ac_time_value"
    )

    ## å®šä¹‰å…³é”®è¯åˆ—è¡¨
    FILTER_KEYWORDS = ['æ°é¥­', 'æ°', 'å¹¿å‘Š', 'æ¨å¹¿', 'å‰ªè¾‘', 'è°ƒè‰²', 'å­—å¹•']

    ## è¿è¡Œä¸»ç¨‹åº
    asyncio.run(main(args.bvid))
```

## å†™åœ¨æœ€å

â€œå¦‚æœæˆ‘èƒ½æ˜ç™½è¿™ç©¶ç«Ÿæ˜¯æ€ä¹ˆå›äº‹å°±å¥½äº†â€ï¼Œé€šå¸¸è¿™ä¸ªæƒ³æ³•ä¼šå‡ºç°åœ¨æœ€å 30% çš„å®ç°ä¸Šã€‚è¯šç„¶ï¼Œå¦‚æœæ²¡æœ‰ AIï¼Œæˆ‘ç»æ— å¯èƒ½æŠŠè¿™äº›çç¢çš„å·¥ä½œç”¨ Python è§£å†³æ‰ï¼Œä½†å®ƒçš„è¡¨ç°ä¾æ—§å·®å£æ°”ã€‚

åœ¨æƒ³æ˜¯ä¸æ˜¯ç”¨ cursor çš„ä½“éªŒä¼šå¥½ä¸Šæ›´å¤šâ€¦â€¦æœ‰ç©ºå†å†™ç¯‡ã€Œéº»ç“œè§†è§’ä¸‹çš„ AI ç¼–ç¨‹ã€èŠèŠï¼Œæ€»ä¹‹è¿™ç¯‡çœŸçš„æ–­æ–­ç»­ç»­å†™äº†å¥½ä¹…ï¼Œå…ˆè¿™æ ·ï¼Œæœ‰ç©ºå†å¡«å‘â€¦â€¦
